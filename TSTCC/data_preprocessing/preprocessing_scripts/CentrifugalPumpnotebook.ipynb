{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO25rUJlHoY7weTWuSn8Vd4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"shKWSVYXDINv","executionInfo":{"status":"ok","timestamp":1718354766849,"user_tz":-60,"elapsed":29063,"user":{"displayName":"Samuel Hesketh Fatchen","userId":"06980961491162386089"}},"outputId":"380a42f0-1189-4583-a5d5-1af84236df7c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fb8kbxrlDG6q","executionInfo":{"status":"ok","timestamp":1718354985664,"user_tz":-60,"elapsed":4226,"user":{"displayName":"Samuel Hesketh Fatchen","userId":"06980961491162386089"}},"outputId":"3d5032fa-db28-4141-9273-c7816ddcfce8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checking directories in: /content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/CentrifugalPump\n","Processing directory: Bi-spectrum counter maps under impeller wearing fault condition\n","Processing directory: bearing outer race wearing fault condition\n","Processing directory: bearing inner race wearing fault condition\n","Processing directory: normal\n","Processing directory: bearing roller wearing fault condition\n","Data sets saved in /content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/TSTCC/data/CentrifugalPump\n","Label mapping: {'Bi-spectrum counter maps under impeller wearing fault condition': 0, 'bearing outer race wearing fault condition': 1, 'bearing inner race wearing fault condition': 2, 'normal': 3, 'bearing roller wearing fault condition': 4}\n","Label 0 (mapped from Bi-spectrum counter maps under impeller wearing fault condition): 255 samples\n","Label 1 (mapped from bearing outer race wearing fault condition): 255 samples\n","Label 2 (mapped from bearing inner race wearing fault condition): 255 samples\n","Label 3 (mapped from normal): 255 samples\n","Label 4 (mapped from bearing roller wearing fault condition): 255 samples\n"]}],"source":["import torch\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from collections import Counter\n","\n","parent_directory = '/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/CentrifugalPump'\n","output_dir = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/TSTCC/data/CentrifugalPump\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","all_data = []\n","all_labels = []\n","sample_length = 400\n","label_mapping = {}\n","\n","print(\"Checking directories in:\", parent_directory)\n","assert os.path.exists(parent_directory), f\"The directory {parent_directory} does not exist.\"\n","\n","for idx, class_dir in enumerate(os.listdir(parent_directory)):\n","    class_path = os.path.join(parent_directory, class_dir)\n","    if os.path.isdir(class_path):\n","        print(f\"Processing directory: {class_dir}\")\n","        label_mapping[class_dir] = idx\n","        for filename in os.listdir(class_path):\n","            if \"ABC\" in filename and filename.endswith(\"#1.TXT\"):\n","                file_path = os.path.join(class_path, filename)\n","                with open(file_path, 'r') as file:\n","                    # Skip first three lines\n","                    for _ in range(3):\n","                        next(file)\n","                    # Read the rest of the data, convert to float\n","                    data = [float(line.strip()) for line in file if line.strip()]\n","                    if data:\n","                        # Ensure that data length is a multiple of sample_length\n","                        num_samples_file = len(data) // sample_length\n","                        data = data[:num_samples_file * sample_length]\n","                        all_data.append(data)\n","                        all_labels.extend([idx] * num_samples_file)  # Assign label idx to each segment\n","\n","if not all_data:\n","    raise ValueError(\"No data files were read. Please check the file paths and formats.\")\n","\n","# Concatenate all data into one long array\n","all_data = np.concatenate(all_data)\n","\n","# Reshape data into samples of 400 data points\n","all_data = all_data.reshape(-1, sample_length)\n","\n","# Normalize the data\n","scaler = MinMaxScaler()\n","all_data = scaler.fit_transform(all_data)\n","\n","# Split data into training, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(all_data, all_labels, test_size=0.4, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Save the datasets as .pt files\n","datasets = {\n","    \"train\": (X_train, y_train),\n","    \"val\": (X_val, y_val),\n","    \"test\": (X_test, y_test)\n","}\n","\n","\n","for set_name, (X, y) in datasets.items():\n","    y = np.array(y)  # Ensure y is a numpy array\n","    torch.save({\n","        \"samples\": torch.from_numpy(X).unsqueeze(1),  # Add channel dimension\n","        \"labels\": torch.from_numpy(y)\n","    }, os.path.join(output_dir, f\"{set_name}.pt\"))\n","\n","print(f\"Data sets saved in {output_dir}\")\n","print(f\"Label mapping: {label_mapping}\")\n","\n","label_counts = Counter(all_labels)\n","for label, count in label_counts.items():\n","    print(f\"Label {label} (mapped from {list(label_mapping.keys())[list(label_mapping.values()).index(label)]}): {count} samples\")\n"]}]}