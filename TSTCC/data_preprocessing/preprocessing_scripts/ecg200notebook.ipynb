{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1GMplQMUlh8EpSa99z5L5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83KPAXGm6LWa","executionInfo":{"status":"ok","timestamp":1718355894167,"user_tz":-60,"elapsed":1896,"user":{"displayName":"Samuel Hesketh Fatchen","userId":"06980961491162386089"}},"outputId":"d5b80379-9a3c-4977-9113-53abc044890f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main\n","[1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1\n"," 0 1 1 1 1 1 1 1 1 0 1 1 0] [0 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n"," 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1\n"," 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 1 0 0 1 1]\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from collections import Counter\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main\n","path = '/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main'\n","os.chdir(path)\n","\n","train_data_path = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/ECG200/ECG200_TRAIN.tsv\"\n","train_data = np.loadtxt(train_data_path)\n","\n","# Extract features (x) and labels (y)\n","train_y = train_data[:, 0].astype(int)\n","train_X = train_data[:, 1:]\n","\n","for i, j in enumerate(train_y):\n","    if j == -1:\n","        train_y[i] = 0\n","\n","\n","test_data_path = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/ECG200/ECG200_TEST.tsv\"\n","test_data = np.loadtxt(test_data_path)\n","\n","# Extract features (x) and labels (y)\n","test_y = test_data[:, 0].astype(int)\n","test_X = test_data[:, 1:]\n","\n","for i, j in enumerate(test_y):\n","    if j == -1:\n","        test_y[i] = 0\n","\n","\n","scaler = MinMaxScaler()\n","train_X = scaler.fit_transform(train_X)\n","\n","scaler = MinMaxScaler()\n","test_X = scaler.fit_transform(test_X)\n","\n","output_dir = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/TSTCC/data/ECG200\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","X_train = train_X\n","y_train = train_y\n","\n","\n","# Split the temporary set into validation and test sets\n","X_val, X_test, y_val, y_test = train_test_split(test_X, test_y, test_size=0.5, random_state=42)\n","\n","\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_train).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_train)\n","torch.save(dat_dict, os.path.join(output_dir, \"train.pt\"))\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_val).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_val)\n","torch.save(dat_dict, os.path.join(output_dir, \"val.pt\"))\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_test).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_test)\n","torch.save(dat_dict, os.path.join(output_dir, \"test.pt\"))\n"]}]}