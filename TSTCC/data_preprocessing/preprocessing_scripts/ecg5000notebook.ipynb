{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1Gzj8f4Y3SZjPdY2HMgAo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UBOns9AO7ONe","executionInfo":{"status":"ok","timestamp":1718355720273,"user_tz":-60,"elapsed":53675,"user":{"displayName":"Samuel Hesketh Fatchen","userId":"06980961491162386089"}},"outputId":"0c9ed450-fc52-42cf-8095-9294d319b600"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main\n","Label 1: 2627 occurrences\n","Label 2: 1590 occurrences\n","Label 3: 86 occurrences\n","Label 4: 175 occurrences\n","Label 5: 22 occurrences\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","\n","from sklearn.model_selection import train_test_split\n","import torch\n","from sklearn.preprocessing import MinMaxScaler\n","from collections import Counter\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main\n","path = '/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main'\n","os.chdir(path)\n","\n","\n","train_data_path = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/ECG5000/ECG5000_TRAIN.tsv\"\n","train_data = np.loadtxt(train_data_path)\n","\n","# Extract features (x) and labels (y)\n","train_y = train_data[:, 0].astype(int) - 1\n","train_X = train_data[:, 1:]\n","\n","test_data_path = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/Data/ECG5000/ECG5000_TEST.tsv\"\n","test_data = np.loadtxt(test_data_path)\n","\n","# Extract features (x) and labels (y)\n","test_y = test_data[:, 0].astype(int) - 1\n","test_X = test_data[:, 1:]\n","\n","\n","scaler = MinMaxScaler()\n","train_X = scaler.fit_transform(train_X)\n","\n","scaler = MinMaxScaler()\n","test_X = scaler.fit_transform(test_X)\n","\n","output_dir = \"/content/drive/MyDrive/FYP_Nur_Time_Series_Representation_using_CL-main/TSTCC/data/ECG5000\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","X_train = train_X\n","y_train = train_y\n","\n","X_val, X_test, y_val, y_test = train_test_split(test_X, test_y, test_size=0.5, random_state=42)\n","\n","# # Count occurrences of each value in array of non-negative ints\n","label_counts = np.bincount(test_y)\n","\n","# # Print the counts\n","for label, count in enumerate(label_counts):\n","    print(f\"Label {label + 1}: {count} occurrences\")\n","\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_train).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_train)\n","torch.save(dat_dict, os.path.join(output_dir, \"train.pt\"))\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_val).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_val)\n","torch.save(dat_dict, os.path.join(output_dir, \"val.pt\"))\n","\n","dat_dict = dict()\n","dat_dict[\"samples\"] = torch.from_numpy(X_test).unsqueeze(1)\n","dat_dict[\"labels\"] = torch.from_numpy(y_test)\n","torch.save(dat_dict, os.path.join(output_dir, \"test.pt\"))\n"]}]}